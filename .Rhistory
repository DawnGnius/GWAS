# data
n <- 100
p <- 100000
# p.afaf   ancestral population allele frequency p
p.afaf <- runif(p, min=0.1, max=0.9)
# data
n <- 1000
n.case <- 500
n.control <- 500
p <- 100000
# p.afaf   ancestral population allele frequency p
p.afaf <- runif(p, min=0.1, max=0.9)
sample.case <- matrix(rep(0, n.case*p))
sample.control <- matrix(rep(0, n.control*p))
# case
idx <- sample(1:2, n.case, prob=c(0.6, 0.4))
idx <- sample(1:2, n.case, prob=c(0.6, 0.4), replace = TRUE)
head(idx, 100)
length(idx==2)
length(which(idx==2))
# data
n <- 1000
n.case <- 500
n.control <- 500
p <- 100000
fst <- 0.01
# p.afaf   ancestral population allele frequency p
p.afaf <- runif(p, min=0.1, max=0.9)
# p.af    allele frequencies
rbeta1 <- function(p){
rbeta(1, p*(1-fst)/fst, (1-p)*(1-fst)/fst)
}
p.af <- unlist(lapply(p.afaf, rbeta1))
knitr::opts_chunk$set(echo = TRUE)
citation("mclust")
num.pc <- 1:200
errorRate <- NULL
for (num in num.pc) {
pcs <- fit.pca$x[,1:num]
# Clustering by PAM with k = 3
fit.pam <- pam(pcs, k = 3, metric = "euclidean")
cluster.pam <- fit.pam$clustering
# Classification error rate
error.PAM <- classError(cluster.pam, data.type)$errorRate
errorRate <- c(errorRate, error.PAM)
}
source('~/Codes/GWAS/Club6_FDP/data_preparation.R', echo=TRUE)
source('~/Codes/GWAS/Club6_FDP/data_preparation.R', echo=TRUE)
source('~/Codes/GWAS/Club6_FDP/data_preparation.R', echo=TRUE)
CHB <- CHB[-1, -1]
head(CHB)
CHB <- read.csv('./Club6_FDP/genevar/CHB.csv')
head(CHB)
CHB <- CHB[, -1]
head(CHB)
head(CEU)
express.CHB <- read.csv('./Club6_FDP/genevar/CHB_180_gene_profile.txt')
head(express.CHB)
express.CHB <- read.csv('./Club6_FDP/genevar/CHB_180_gene_profile.txt')
express.CEU <- read.csv('./Club6_FDP/genevar/CEUp_240_gene_profile.txt')
tt <- read.csv('./Club6_FDP/genevar/tmp.txt')
View(tt)
tt <- read.csv('./Club6_FDP/genevar/tmp.txt', sep='\t')
View(tt)
source('~/Codes/GWAS/Club6_FDP/realData.R', echo=TRUE)
express.JPT <- read.csv('./Club6_FDP/genevar/JPT_180_gene_profile.txt', sep='\t')
express.YRI <- read.csv('./Club6_FDP/genevar/YRIp_240_gene_profile.txt', sep='\t')
rm('express.CEU')
rm('tt')
express.CEU <- read.csv('./Club6_FDP/genevar/CEUp_240_gene_profile.txt', sep='\t')
express.CEU <- read.csv('./Club6_FDP/genevar/CEUp_240_gene_profile.txt', sep='\t')
rm('microarray')
save.image("~/Codes/GWAS/Club6_FDP/genevar/dat.RData")
knitr::opts_chunk$set(echo = TRUE)
test <- read.csv('test.txt', header = TRUE)
View(test)
test <- read.csv('test.txt', header = TRUE, sep=" ")
train <- read.csv('train.txt', header=TRUE, sep=" ")
train <- read.csv('training.txt', header=TRUE, sep=" ")
Y.test <- test[,-1]
View(Y.test)
View(train)
X.test <- test[, 1]
Y.test <- test[,-1]
X.train <- train[, 1]
Y.train <- train[,-1]
a <- read.table('test.txt', header = TRUE)
setwd("~/Codes/GWAS/HW3")
a <- read.table('test.txt', header = TRUE)
lm(Y.train ~ X.train)
Y.test <- test[, 1]
X.test <- test[,-1]
Y.train <- train[, 1]
X.train <- train[,-1]
lm(Y.train ~ X.train)
myData <- data.frame(x=X.train, y=Y.train)
lm(y ~ x, data=myData)
lm(Y ~ X1 + ... + X20, train=myData)
lm(Y ~ X1 + ... + X20, data=train)
lm(Y ~ X1 + X20, data=train)
paste0("Y~",paste("X",1:20,sep="",collapse="+"))
lm(paste0("Y~",paste("X",1:20,sep="",collapse="+")), data=train)
lm(paste0("Y~",paste("X",1:20,sep="",collapse="+")), data=train)
fit.lm <- lm(paste0("Y~",paste("X",1:20,sep="",collapse="+")), data=train)
summary(fit.lm)
library(glmnet)
cv.glmnet(X.train,Y.train)
cv.glmnet(X.train,Y.train, family='mgaussian')
glmnet(X.train,Y.train, family='mgaussian')
glmnet(X.train,Y.train)
X.train <- as.matrix(train[,-1])
X.test <- as.matrix(test[,-1])
glmnet(X.train,Y.train)
cv.glmnet(X.train,Y.train)
fit.lasso.cv <- cv.glmnet(X.train,Y.train)
install.packages("msgps")
library(ncvreg)
install.packages("ncvreg")
library(glmnet)
fit.lasso.cv <- cv.glmnet(X.train,Y.train)
summary(fit.lasso.cv)
library(ncvreg)
fit.lasso.cv$lambda.min
fit.lasso.cv$nzero
glmnet(X.train,Y.train, lambda=fit.lasso.cv$lambda.min)
fit.lasso <- glmnet(X.train,Y.train, lambda=fit.lasso.cv$lambda.min)
fit.lasso$beta
which(fit.lasso$beta != 0)
View(X.test)
colnames(X.train)[which(fit.lasso$beta != 0)]
fit.lasso$beta[which(fit.lasso$beta != 0)]
res.lasso <- fit.lasso$beta[which(fit.lasso$beta != 0)]
names(res.lasso) <- colnames(X.train)[which(fit.lasso$beta != 0)]
res.lasso
predict.glmnet(fit.lasso, X.test)
library(ncvreg)
ncvreg(X.train, Y.train, family="gaussian", penalty="SCAD")
fit.scad <- ncvreg(X.train, Y.train, family="gaussian", penalty="SCAD")
View(fit.scad)
fit.scad$loss
which.min(fit.scad$loss)
fit.scad$lambda
fit.scad <- ncvreg(X.train, Y.train, family="gaussian", penalty="SCAD", lambda=0.03)
fit.scad
View(fit.scad)
fit.scad$beta
which(fit.scad$beta != 0)
fit.scad <- ncvreg(X.train, Y.train, family="gaussian", penalty="SCAD", lambda=0.03, intercept=FLASE)
which(fit.scad$beta[2:21] != 0)
res.scad <- fit.scad$beta[which(fit.scad$beta[2:21] != 0)]
names(res.scad) <- colnames(X.train)[which(fit.scad$beta[2:21] != 0)]
res.scad
res.scad <- fit.scad$beta[which(fit.scad$beta[2:21] != 0)+1]
res.scad
res.scad <- fit.scad$beta[which(fit.scad$beta[2:21] != 0)+1]
names(res.scad) <- colnames(X.train)[which(fit.scad$beta[2:21] != 0)]
res.scad
fit.mad <- ncvreg(X.train, Y.train, family="gaussian", penalty="MAD", lambda=0.03, intercept=FLASE)
fit.mad <- ncvreg(X.train, Y.train, family="gaussian", penalty="MCP", lambda=0.03, intercept=FLASE)
fit.mcp <- ncvreg(X.train, Y.train, family="gaussian", penalty="MCP", lambda=0.03)
res.mcp <- fit.mcp$beta[which(fit.mcp$beta[2:21] != 0)+1]
res.mcp
fit.mcp <- ncvreg(X.train, Y.train, family="gaussian", penalty="MCP", lambda=0.03)
res.mcp <- fit.mcp$beta[which(fit.mcp$beta[2:21] != 0)+1]
names(res.mcp) <- colnames(X.train)[which(fit.mcp$beta[2:21] != 0)]
print(res.mcp)
library(glmnet)
fit.lasso.cv <- cv.glmnet(X.train, Y.train)
fit.lasso <- glmnet(X.train,Y.train, lambda=fit.lasso.cv$lambda.min)
res.lasso <- fit.lasso$beta[which(fit.lasso$beta != 0)]
names(res.lasso) <- colnames(X.train)[which(fit.lasso$beta != 0)]
print(res.lasso)
Y.hat.lasso <- predict.glmnet(fit.lasso, X.test)
library(ncvreg)
fit.scad <- ncvreg(X.train, Y.train, family="gaussian", penalty="SCAD", lambda=0.03)
res.scad <- fit.scad$beta[which(fit.scad$beta[2:21] != 0)+1]
names(res.scad) <- colnames(X.train)[which(fit.scad$beta[2:21] != 0)]
print(res.scad)
fit.mcp <- ncvreg(X.train, Y.train, family="gaussian", penalty="MCP", lambda=0.03)
res.mcp <- fit.mcp$beta[which(fit.mcp$beta[2:21] != 0)+1]
names(res.mcp) <- colnames(X.train)[which(fit.mcp$beta[2:21] != 0)]
print(res.mcp)
cv.ncvreg(X.train, Y.train, family="gaussian", penalty="SCAD")
library(glmnet)
fit.lasso.cv <- cv.glmnet(X.train, Y.train)
fit.lasso <- glmnet(X.train,Y.train, lambda=fit.lasso.cv$lambda.min)
res.lasso <- fit.lasso$beta[which(fit.lasso$beta != 0)]
names(res.lasso) <- colnames(X.train)[which(fit.lasso$beta != 0)]
print(res.lasso)
Y.hat.lasso <- predict.glmnet(fit.lasso, X.test)
library(ncvreg)
fit.scad.cv <- cv.ncvreg(X.train, Y.train, family="gaussian", penalty="SCAD")
fit.scad <- ncvreg(X.train, Y.train, family="gaussian", penalty="SCAD", lambda=fit.scad.cv$lambda.min)
res.scad <- fit.scad$beta[which(fit.scad$beta[2:21] != 0)+1]
names(res.scad) <- colnames(X.train)[which(fit.scad$beta[2:21] != 0)]
print(res.scad)
fit.mcp.cv <- cv.ncvreg(X.train, Y.train, family="gaussian", penalty="MCP")
fit.mcp <- ncvreg(X.train, Y.train, family="gaussian", penalty="MCP", lambda=fit.mcp.cv$lambda.min)
res.mcp <- fit.mcp$beta[which(fit.mcp$beta[2:21] != 0)+1]
names(res.mcp) <- colnames(X.train)[which(fit.mcp$beta[2:21] != 0)]
print(res.mcp)
Y.hat.lasso <- predict.glmnet(fit.lasso, X.test)
Y.hat.scad <- predict.ncvreg(fit.scad, X.test)
Y.hat.scad <- predict.ncvreg(fit.scad, X.test)
predict.ncvreg
predict(fit.scad, X.test)
Y.hat.lasso <- predict.glmnet(fit.lasso, X.test)
Y.hat.scad <- predict(fit.scad, X.test)
Y.hat.mcp <- predict(fit.mcp, X.test)
mse(Y.hat.lasso-Y.test)
(Y.hat.lasso-Y.test)
(Y.hat.lasso-Y.test)^2
sum((Y.hat.lasso-Y.test)^2)
sum((Y.hat.lasso-Y.test)^2)
sum((Y.hat.scad-Y.test)^2)
sum((Y.hat.mcp-Y.test)^2)
sum((Y.hat.lasso-Y.test)^2) / 100
sum((Y.hat.scad-Y.test)^2) / 100
sum((Y.hat.mcp-Y.test)^2) / 100
err <- c(lasso=sum((Y.hat.lasso-Y.test)^2) / 100, scad=sum((Y.hat.scad-Y.test)^2) / 100, mcp=sum((Y.hat.mcp-Y.test)^2) / 100)
err
Y.hat.lasso <- predict.glmnet(fit.lasso, X.test)
Y.hat.scad <- predict(fit.scad, X.test)
Y.hat.mcp <- predict(fit.mcp, X.test)
print("Predict Error")
err <- c(lasso=sum((Y.hat.lasso-Y.test)^2) / 100, scad=sum((Y.hat.scad-Y.test)^2) / 100, mcp=sum((Y.hat.mcp-Y.test)^2) / 100)
Y.hat.lasso <- predict.glmnet(fit.lasso, X.test)
Y.hat.scad <- predict(fit.scad, X.test)
Y.hat.mcp <- predict(fit.mcp, X.test)
err <- c(lasso=sum((Y.hat.lasso-Y.test)^2) / 100, scad=sum((Y.hat.scad-Y.test)^2) / 100, mcp=sum((Y.hat.mcp-Y.test)^2) / 100)
print("Predict Error")
print(err)
knitr::opts_chunk$set(echo = TRUE)
test <- read.csv('test.txt', header = TRUE, sep=" ")
train <- read.csv('training.txt', header=TRUE, sep=" ")
Y.test <- test[, 1]
X.test <- as.matrix(test[,-1])
Y.train <- train[, 1]
X.train <- as.matrix(train[,-1])
a <- lars(X_train, Y_train)
library(lars)
a <- lars(X_train, Y_train)
a <- lars(X.train, Y.train)
plot(a)
a <- lars(X.train, Y.train, lambda=0.3)
a$Cp
a$lambda[9]
a
a$beta[9,]
install.packages("sofar")
install.packages("rrpack")
